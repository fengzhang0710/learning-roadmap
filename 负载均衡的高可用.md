##  负载均衡的高可用



### 集群：使用集群，可以满足单机算力不足的情况，简单的买机器，是最廉价的解决方案。



```shell
+----------+          +---------------+
|					 |          |								|
|          +---------->   Tomcat1     |
|          |          |								|
|  NGINX   |          +---------------+
|          |
| upstream |          +---------------+
|          |          |               |
|          +---------->    Tomcat2    |
|					 |          |               |
+----------+          +---------------+
```



有了集群，我们就需要负载均衡一下这个集群，每个服务器都只处理一部分数据，避免请求分配不均匀的情况出现

1.提高可用性，避免单点故障

2.同城、异地容灾





### 负载均衡的问题

1.共享数据的解决方案

​	a.session共享，放到一个自定义的session容器里面

​	b.session复制，不太行

​	c.路由，把一个session放到同一个服务器里面(换ip等操作会导致重新登录)

2.共享数据后的问题

​	a.要序列化

​	b.要控制资源粒度



###怎么实现负载均衡

​	1.基于解析服务

​		请求不会直接到达前置服务器，我们会用dns来代表服务名称，通过解析域名，让服务的注册和发现来解决服务路由，就是服务的注册中心

​	2.3/4层的转发

​		lvs，效率最好，最普遍。负载均衡只需要重新封装一下3/4层的协议，不会产生流量，也不需要维护两份连接句柄，在linux的内核态完成

​	3.七层转发

mysql,redis自己实现的协议也都是七层转发；nginx和httpd解析七层协议。

相比第三四层的协议，七层可以得到最大灵活度，解析HTTP协议获得URL获得用户传递过来某一个参数（比如sessionid等），简单的脚本或者正则就能定义个性化的转发策略。同样MYSQL proxy，AMIBA这种代理中间件通过解析MYSQL协议获得发送的SQL，通过简单的脚本语言（比如mysql 使用lua...）可以很灵活的更具SQL的内容来确定具体的后方服务器，比如读写分离；

需要注意的是：七层转发会产生流量的，同时七层代理服务器需要维护前后两个连接句柄（收到用户请求产生并维持一个服务连接，同时作为客户端向后端服务发起请求是另外一个连接），这种转发模式一般在用户层实现，系统需要将内核层的数据拷贝到用户空间，完成解析和处理，再将用户空间的数据拷贝到内核空间，由linux的网络子系统转发，所以我们说他会产生流量，相比三四层的转发其代价就要高很多。

​	4.基于客户端的路由

我们在客户端实现请求具体去哪一个服务器，通过配置一个服务器集群列表或者从＂名字服务器＂查找和下载这个列表，然后由客户端决定具体选择哪条线路的路由。redis官方的＂哨兵＂方案就是这种模式。这种方式相比中间件（代理／转发）的方式的代价就是在一定程度上改动一些代码；



### 负载均衡器的高可用

Ngnix+keepalived

Keepalived，ARRP协议，虚拟出一个路由器，保证两个主机是双热的状态，对外统一提供一个虚拟的路由ip







lvs的三种工作模式和十种调度算法

https://blog.csdn.net/weixin_40470303/article/details/80541639













通过apollo配合环境变量，完成配置文件的切换功能

​	apollo当然可以做的更多：灰度发布，a/b测试等等

